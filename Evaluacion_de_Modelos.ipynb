{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20df5e90",
   "metadata": {},
   "source": [
    "# 7. Evaluación de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee88b15",
   "metadata": {},
   "source": [
    "Tras el proceso de **Validación Avanzada, Tuning e Interpretabilidad**, se realizó una evaluación comparativa de los tres modelos optimizados —**KNN**, **Random Forest** y **XGBoost**— con el propósito de analizar su desempeño predictivo sobre el conjunto de prueba.\n",
    "Esta etapa buscó determinar la capacidad de generalización de los modelos a partir de métricas de clasificación, curvas ROC–AUC y análisis de errores, siguiendo las recomendaciones metodológicas establecidas.\n",
    "\n",
    "\n",
    "#### **7.1 Matriz de Confusión**\n",
    "\n",
    "Las matrices de confusión permitieron observar la distribución de aciertos y errores en las tres categorías (`Good`, `Poor`, `Standard`), reflejando la eficacia del modelo para identificar correctamente cada clase.\n",
    "En términos generales, los tres algoritmos presentaron **altas tasas de acierto en la clase mayoritaria (`Standard`)**, aunque con matices distintivos:\n",
    "\n",
    "| Modelo            | Clase con mayor precisión | Principales errores observados                                                   |\n",
    "| :---------------- | :------------------------ | :------------------------------------------------------------------------------- |\n",
    "| **KNN**           | `Standard`                | Confusión leve entre `Good` y `Poor` debido a similitud vectorial.               |\n",
    "| **Random Forest** | `Standard`                | Sobreclasificación moderada de `Good` y subestimación de `Poor`.                 |\n",
    "| **XGBoost**       | `Standard`                | Reducción significativa de falsos positivos en `Poor` y mejor separación global. |\n",
    "\n",
    "El modelo **XGBoost** demostró una matriz más equilibrada y consistente, reflejando un mejor ajuste general entre clases y reduciendo los errores de clasificación cruzada.\n",
    "\n",
    "\n",
    "#### **7.2 Curvas ROC y Valores AUC**\n",
    "\n",
    "Las curvas ROC multiclase se estimaron utilizando la estrategia *one-vs-rest*, obteniendo las siguientes áreas bajo la curva (AUC) promedio para cada modelo:\n",
    "\n",
    "| Modelo            | AUC Promedio |\n",
    "| :---------------- | :----------: |\n",
    "| **KNN**           |     0.83     |\n",
    "| **Random Forest** |     0.85     |\n",
    "| **XGBoost**       |   **0.88**   |\n",
    "\n",
    "El **XGBoost** alcanzó el valor AUC más alto, lo que confirma su **mayor capacidad discriminativa entre clases** y un equilibrio más eficiente entre sensibilidad y especificidad.\n",
    "\n",
    "\n",
    "#### **7.3 Tabla Comparativa de Métricas**\n",
    "\n",
    "| Modelo                     | Accuracy | Precision |  Recall  | **F1-score (Principal)** |    AUC   |\n",
    "| :------------------------- | :------: | :-------: | :------: | :----------------------: | :------: |\n",
    "| **KNN Avanzado**           |   0.77   |    0.76   |   0.77   |           0.769          |   0.83   |\n",
    "| **Random Forest Avanzado** |   0.77   |    0.76   |   0.76   |           0.763          |   0.85   |\n",
    "| **XGBoost Avanzado**       | **0.78** |  **0.78** | **0.77** |         **0.771**        | **0.88** |\n",
    "\n",
    "El modelo **XGBoost Avanzado** obtuvo el mejor rendimiento global en todas las métricas, destacándose por su **mayor F1-score y AUC**, superando levemente a los demás algoritmos en precisión y balance entre clases.\n",
    "\n",
    "\n",
    "#### **7.4 Justificación de la Métrica Principal**\n",
    "\n",
    "La métrica principal seleccionada fue el **F1-score (macro promedio)** debido a que:\n",
    "\n",
    "* Evalúa de manera **equilibrada el desempeño en cada clase**, evitando el sesgo hacia la categoría mayoritaria.\n",
    "* Combina **precisión** (proporción de predicciones correctas) y **recall** (capacidad de detectar verdaderos positivos) en un solo indicador robusto.\n",
    "* Resulta **más apropiada para conjuntos de datos desbalanceados**, como el de este estudio, en comparación con el accuracy.\n",
    "\n",
    "De este modo, el F1-score permitió una valoración justa y generalizable del rendimiento de cada modelo, siendo el criterio base para la **selección del modelo óptimo** en la siguiente fase."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
